{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Project\n",
    "Comparing various Noise Reduction Techniques with each other using various kinds of metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepearing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /var/home/noshamedevil/miniconda3/envs/tf/lib/python3.10/site-packages (0.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio files combined and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def combine_audio_with_noise(original_folder, noise_folder, output_folder, noise_reduction_db=10):\n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # List audio files in the original and noise folders\n",
    "    original_files = [f for f in os.listdir(original_folder) if f.endswith(\".wav\")]\n",
    "    noise_files = [f for f in os.listdir(noise_folder) if f.endswith(\".wav\")]\n",
    "\n",
    "    if not original_files:\n",
    "        print(\"No original audio files found in the folder.\")\n",
    "        return\n",
    "\n",
    "    if not noise_files:\n",
    "        print(\"No noise files found in the folder.\")\n",
    "        return\n",
    "\n",
    "    for original_file in original_files:\n",
    "        # Load the original audio\n",
    "        original_path = os.path.join(original_folder, original_file)\n",
    "        original_audio = AudioSegment.from_wav(original_path)\n",
    "\n",
    "        # Select a random noise file\n",
    "        noise_file = noise_files[0]  # Use the first noise file, or implement random selection\n",
    "        noise_path = os.path.join(noise_folder, noise_file)\n",
    "        noise_audio = AudioSegment.from_wav(noise_path)\n",
    "\n",
    "        # Reduce the volume of the noise\n",
    "        noise_audio = noise_audio - noise_reduction_db\n",
    "\n",
    "        # Adjust the length of the noise to match the original audio\n",
    "        if len(noise_audio) < len(original_audio):\n",
    "            noise_audio = noise_audio * (len(original_audio) // len(noise_audio) + 1)\n",
    "\n",
    "        noise_audio = noise_audio[:len(original_audio)]\n",
    "\n",
    "        # Combine the original audio and noise\n",
    "        combined_audio = original_audio.overlay(noise_audio)\n",
    "\n",
    "        # Save the combined audio\n",
    "        output_path = os.path.join(output_folder, f\"combined_{original_file}\")\n",
    "        combined_audio.export(output_path, format=\"wav\")\n",
    "\n",
    "    print(\"Audio files combined and saved successfully.\")\n",
    "\n",
    "# Example usage\n",
    "original_folder = \"./MS-SNSD-master/clean_test\"\n",
    "noise_folder = \"./MS-SNSD-master/noise_test\"\n",
    "output_folder = \"./MS-SNSD-master/combined_test\"\n",
    "combine_audio_with_noise(original_folder, noise_folder, output_folder, noise_reduction_db=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technique 1 STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import soundfile\n",
    "import time\n",
    "from datetime import timedelta as td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fftnoise(f):\n",
    "    f = np.array(f, dtype=\"complex\")\n",
    "    Np = (len(f) - 1) // 2\n",
    "    phases = np.random.rand(Np) * 2 * np.pi\n",
    "    phases = np.cos(phases) + 1j * np.sin(phases)\n",
    "    f[1: Np + 1] *= phases\n",
    "    f[-1: -1 - Np: -1] = np.conj(f[1: Np + 1])\n",
    "    return np.fft.ifft(f).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def band_limited_noise(min_freq, max_freq, samples=1024, samplerate=1):\n",
    "    freqs = np.abs(np.fft.fftfreq(samples, 1 / samplerate))\n",
    "    f = np.zeros(samples)\n",
    "    f[np.logical_and(freqs >= min_freq, freqs <= max_freq)] = 1\n",
    "    return fftnoise(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _stft(y, n_fft, hop_length, win_length):\n",
    "    return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _istft(y, hop_length, win_length):\n",
    "    return librosa.istft(y, hop_length=hop_length, win_length=win_length)\n",
    "\n",
    "\n",
    "def _amp_to_db(x):\n",
    "    return librosa.amplitude_to_db(x, ref=1.0, amin=1e-20, top_db=80.0)\n",
    "\n",
    "\n",
    "def _db_to_amp(x):\n",
    "    return librosa.db_to_amplitude(x, ref=1.0)\n",
    "    \n",
    "\n",
    "def plot_spectrogram(signal, title):\n",
    "    fig, ax = plt.subplots(figsize=(20, 4))\n",
    "    cax = ax.matshow(\n",
    "        signal,\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "        cmap=plt.cm.seismic,\n",
    "        vmin=-1 * np.max(np.abs(signal)),\n",
    "        vmax=np.max(np.abs(signal)),\n",
    "    )\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_statistics_and_filter(mean_freq_noise, std_freq_noise, noise_thresh, smoothing_filter):\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(20, 4))\n",
    "    ax[0].plot(std_freq_noise, label=\"Std. power of noise\")\n",
    "    ax[0].plot(noise_thresh, label=\"Noise threshold (by frequency)\")\n",
    "    ax[0].set_title(\"Threshold for mask\")\n",
    "    ax[0].legend()\n",
    "    cax = ax[1].matshow(smoothing_filter, origin=\"lower\")\n",
    "    fig.colorbar(cax)\n",
    "    ax[1].set_title(\"Filter for smoothing Mask\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_noise(\n",
    "    audio_clip, \n",
    "    noise_clip,\n",
    "    n_grad_freq=2,\n",
    "    n_grad_time=4,\n",
    "    n_fft=512,\n",
    "    win_length=512,\n",
    "    hop_length=512//4,\n",
    "    n_std_thresh=0.5,\n",
    "    prop_decrease=0.8,\n",
    "    verbose=False,\n",
    "    visual=False,\n",
    "):\n",
    "    noise_stft = _stft(noise_clip, n_fft, hop_length, win_length)\n",
    "    noise_stft_db = _amp_to_db(np.abs(noise_stft))\n",
    "\n",
    "    mean_freq_noise = np.mean(noise_stft_db, axis=1)\n",
    "    std_freq_noise = np.std(noise_stft_db, axis=1)\n",
    "    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n",
    "\n",
    "    sig_stft = _stft(audio_clip, n_fft, hop_length, win_length)\n",
    "    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n",
    "\n",
    "    mask_gain_dB = np.min(_amp_to_db(np.abs(sig_stft)))\n",
    "\n",
    "    smoothing_filter = np.outer(\n",
    "        np.concatenate([\n",
    "            np.linspace(0, 1, n_grad_freq + 1, endpoint=False),\n",
    "            np.linspace(1, 0, n_grad_freq + 2),\n",
    "        ])[1:-1],\n",
    "        np.concatenate([\n",
    "            np.linspace(0, 1, n_grad_time + 1, endpoint=False),\n",
    "            np.linspace(1, 0, n_grad_time + 2),\n",
    "        ])[1:-1],\n",
    "    )\n",
    "    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n",
    "\n",
    "    db_thresh = np.repeat(\n",
    "        np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n",
    "        np.shape(sig_stft_db)[1],\n",
    "        axis=0,\n",
    "    ).T\n",
    "\n",
    "    sig_mask = sig_stft_db < db_thresh\n",
    "    sig_mask = scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n",
    "    sig_mask = sig_mask * prop_decrease\n",
    "\n",
    "    sig_stft_db_masked = (\n",
    "        sig_stft_db * (1 - sig_mask)\n",
    "        + np.ones(np.shape(mask_gain_dB)) * mask_gain_dB * sig_mask\n",
    "    )\n",
    "    sig_imag_masked = np.imag(sig_stft) * (1 - sig_mask)\n",
    "    sig_stft_amp = (_db_to_amp(sig_stft_db_masked) * np.sign(sig_stft)) + (1j * sig_imag_masked)\n",
    "\n",
    "    recovered_signal = _istft(sig_stft_amp, hop_length, win_length)\n",
    "    recovered_spec = _amp_to_db(\n",
    "        np.abs(_stft(recovered_signal, n_fft, hop_length, win_length))\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        plot_spectrogram(noise_stft_db, 'Noise STFT (dB)')\n",
    "        plot_spectrogram(recovered_spec, 'Recovered Spectrogram (dB)')\n",
    "    \n",
    "    return recovered_signal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp0.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp0.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp1.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp1.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp10.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp10.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp11.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp11.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp12.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp12.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp13.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp13.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp14.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp14.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp15.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp15.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp16.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp16.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp17.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp17.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp18.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp18.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp19.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp19.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp2.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp2.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp20.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp20.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp3.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp3.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp4.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp4.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp5.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp5.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp6.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp6.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp7.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp7.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp8.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp8.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp9.wav...\n",
      "Saved denoised file to ./output/STFT/denoised_combined_clnsp9.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def process_folder(input_folder, output_folder, n_fft=512, hop_length=128, win_length=512):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.wav'):  # Ensure only WAV files are processed\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            output_path = os.path.join(output_folder, f\"denoised_{file_name}\")\n",
    "            \n",
    "            print(f\"Processing {input_path}...\")\n",
    "            data, sr = librosa.load(input_path, sr=None)\n",
    "            denoised = remove_noise(data, data, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
    "            sf.write(output_path, denoised, sr)\n",
    "            print(f\"Saved denoised file to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = './MS-SNSD-master/combined_test/'\n",
    "    output_folder = './output/STFT/'\n",
    "    \n",
    "    process_folder(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technique 2 FFT + DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp0.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp0.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp1.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp1.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp10.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp10.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp11.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp11.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp12.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp12.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp13.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp13.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp14.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp14.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp15.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp15.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp16.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp16.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp17.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp17.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp18.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp18.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp19.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp19.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp2.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp2.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp20.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp20.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp3.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp3.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp4.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp4.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp5.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp5.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp6.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp6.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp7.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp7.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp8.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp8.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp9.wav...\n",
      "Saved denoised file to ./output/FFT/denoised_combined_clnsp9.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy.fft import fft, ifft\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "def fft_denoise(audio, sample_rate, cutoff_frequency=2000):\n",
    "    # Perform FFT\n",
    "    audio_fft = fft(audio)\n",
    "    \n",
    "    # Frequency filtering\n",
    "    frequency_indices = np.fft.fftfreq(len(audio), d=1/sample_rate)\n",
    "    high_amplitude_indices = np.abs(audio_fft) > np.percentile(np.abs(audio_fft), 99)\n",
    "    audio_fft[high_amplitude_indices] *= 0.1  # Reduce high amplitude components\n",
    "\n",
    "    # Perform inverse FFT\n",
    "    filtered_audio = np.real(ifft(audio_fft))\n",
    "    return filtered_audio\n",
    "\n",
    "def process_folder_fft_dnn(input_folder, output_folder, cutoff_frequency=2000):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.wav'):  # Ensure only WAV files are processed\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            output_path = os.path.join(output_folder, f\"denoised_{file_name}\")\n",
    "            \n",
    "            print(f\"Processing {input_path}...\")\n",
    "            sample_rate, audio = wavfile.read(input_path)\n",
    "            denoised_audio = fft_denoise(audio, sample_rate, cutoff_frequency=cutoff_frequency)\n",
    "            wavfile.write(output_path, sample_rate, denoised_audio.astype(np.int16))\n",
    "            print(f\"Saved denoised file to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = './MS-SNSD-master/combined_test/'\n",
    "    output_folder = './output/FFT/'\n",
    "    \n",
    "    process_folder_fft_dnn(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 19:23:38.970139: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734719019.040127   16456 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734719019.059765   16456 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-20 19:23:39.220158: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import scipy.io.wavfile\n",
    "import scipy.signal\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sphfile import SPHFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stackLayers function\n",
    "def stackLayers(layerSet):\n",
    "    stack = layerSet[0]\n",
    "    for i in range(1, len(layerSet)):\n",
    "        stack = layerSet[i](stack)\n",
    "    return stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from: ./TIMIT/TRAIN\n",
      "Loading testing data from: ./TIMIT/TEST\n"
     ]
    }
   ],
   "source": [
    "# Set the working directory for TIMIT dataset\n",
    "train_cwd = './TIMIT/TRAIN'  # Adjust path to TIMIT training data\n",
    "test_cwd = './TIMIT/TEST'    # Adjust path to TIMIT test data\n",
    "\n",
    "# Load the training dataset (TIMIT)\n",
    "trainSoundClips = []\n",
    "print(f\"Loading training data from: {train_cwd}\")\n",
    "for soundFile in Path(train_cwd).rglob('*.wav'):\n",
    "    trainSoundClips += [scipy.io.wavfile.read(soundFile)]\n",
    "\n",
    "# Load the testing dataset (TIMIT)\n",
    "testSoundClips = []\n",
    "print(f\"Loading testing data from: {test_cwd}\")\n",
    "for soundFile in Path(test_cwd).rglob('*.wav'):\n",
    "    testSoundClips += [scipy.io.wavfile.read(soundFile)]\n",
    "\n",
    "# Assuming the dataset rate is the same for all files\n",
    "dataRate = trainSoundClips[0][0]\n",
    "\n",
    "# Extracting audio data from the loaded clips\n",
    "trainClips = [i[1] for i in trainSoundClips]\n",
    "testClips = [i[1] for i in testSoundClips]\n",
    "\n",
    "# Merge training data and validation split (90% training, 10% validation)\n",
    "mergedSpeech = np.concatenate(trainClips, axis=0)\n",
    "validationSpeech = mergedSpeech[mergedSpeech.shape[0] * 9 // 10:]\n",
    "mergedSpeech = mergedSpeech[:mergedSpeech.shape[0] * 9 // 10]\n",
    "\n",
    "normalizingFactor = np.std(mergedSpeech)\n",
    "noisingFactor = 0.15  # Can adjust based on noise level\n",
    "clipLength = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sampleGenerator function\n",
    "def sampleGenerator(originalSound, sampleLength, noisingFactor, normalizingFactor, batchSize=32, firstFixed=None):\n",
    "    while True:\n",
    "        indices = np.random.randint(low=0, high=originalSound.shape[0] - sampleLength, size=batchSize).tolist()\n",
    "        if firstFixed is not None:\n",
    "            indices[0] = firstFixed\n",
    "        samples = np.array([originalSound[index:index + sampleLength] for index in indices])\n",
    "        noise = np.random.normal(loc=0, scale=noisingFactor * normalizingFactor, size=samples.shape)\n",
    "        yield ((samples + noise) / normalizingFactor, samples / normalizingFactor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734719030.085016   16456 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5467 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "/home/noshamedevil/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,601</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m1,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │         \u001b[38;5;34m1,601\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">618,049</span> (2.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m618,049\u001b[0m (2.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">618,049</span> (2.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m618,049\u001b[0m (2.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model layers (already provided in the code)\n",
    "denoiserLayers = [\n",
    "    keras.layers.Input(shape=(clipLength,)),\n",
    "    keras.layers.Reshape((clipLength, 1)),\n",
    "\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=25, padding='same'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=25, padding='same'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dropout(.4),\n",
    "\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=25, padding='same'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=25, padding='same'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dropout(.4),\n",
    "\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=25, padding='same'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=25, padding='same'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dropout(.4),\n",
    "\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=25, padding='same'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "\n",
    "    keras.layers.Conv1D(filters=1, kernel_size=25, padding='same'),\n",
    "    keras.layers.Dropout(.4),\n",
    "\n",
    "    keras.layers.Reshape((clipLength,)),\n",
    "]\n",
    "\n",
    "# Now you can use stackLayers function to build the model\n",
    "denoiser = keras.models.Model(inputs=denoiserLayers[0], outputs=stackLayers(denoiserLayers))\n",
    "denoiser.compile(optimizer=keras.optimizers.Adam(.0001, decay=1e-7), loss='mse', metrics=['mse'])\n",
    "denoiser.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "512/512 - 23s - 45ms/step - loss: 0.4093 - mse: 0.4093 - val_loss: 0.1460 - val_mse: 0.1460\n",
      "Epoch 2/30\n",
      "512/512 - 23s - 46ms/step - loss: 0.4184 - mse: 0.4184 - val_loss: 0.1511 - val_mse: 0.1511\n",
      "Epoch 3/30\n",
      "512/512 - 24s - 47ms/step - loss: 0.4232 - mse: 0.4232 - val_loss: 0.1416 - val_mse: 0.1416\n",
      "Epoch 4/30\n",
      "512/512 - 29s - 57ms/step - loss: 0.4155 - mse: 0.4155 - val_loss: 0.1534 - val_mse: 0.1534\n",
      "Epoch 5/30\n",
      "512/512 - 39s - 77ms/step - loss: 0.4106 - mse: 0.4106 - val_loss: 0.1434 - val_mse: 0.1434\n",
      "Epoch 6/30\n",
      "512/512 - 45s - 88ms/step - loss: 0.4085 - mse: 0.4085 - val_loss: 0.1530 - val_mse: 0.1530\n",
      "Epoch 7/30\n",
      "512/512 - 54s - 105ms/step - loss: 0.4318 - mse: 0.4318 - val_loss: 0.1698 - val_mse: 0.1698\n",
      "Epoch 8/30\n",
      "512/512 - 59s - 114ms/step - loss: 0.4099 - mse: 0.4099 - val_loss: 0.1701 - val_mse: 0.1701\n",
      "Epoch 9/30\n",
      "512/512 - 61s - 119ms/step - loss: 0.4136 - mse: 0.4136 - val_loss: 0.1477 - val_mse: 0.1477\n",
      "Epoch 10/30\n",
      "512/512 - 60s - 117ms/step - loss: 0.4225 - mse: 0.4225 - val_loss: 0.1513 - val_mse: 0.1513\n",
      "Epoch 11/30\n",
      "512/512 - 63s - 123ms/step - loss: 0.4151 - mse: 0.4151 - val_loss: 0.1549 - val_mse: 0.1549\n",
      "Epoch 12/30\n",
      "512/512 - 65s - 126ms/step - loss: 0.4077 - mse: 0.4077 - val_loss: 0.1468 - val_mse: 0.1468\n",
      "Epoch 13/30\n",
      "512/512 - 67s - 130ms/step - loss: 0.4133 - mse: 0.4133 - val_loss: 0.1676 - val_mse: 0.1676\n",
      "Epoch 14/30\n",
      "512/512 - 68s - 133ms/step - loss: 0.4017 - mse: 0.4017 - val_loss: 0.1475 - val_mse: 0.1475\n",
      "Epoch 15/30\n",
      "512/512 - 71s - 138ms/step - loss: 0.4241 - mse: 0.4241 - val_loss: 0.1523 - val_mse: 0.1523\n",
      "Epoch 16/30\n",
      "512/512 - 74s - 144ms/step - loss: 0.4082 - mse: 0.4082 - val_loss: 0.1569 - val_mse: 0.1569\n",
      "Epoch 17/30\n",
      "512/512 - 75s - 146ms/step - loss: 0.4121 - mse: 0.4121 - val_loss: 0.1504 - val_mse: 0.1504\n",
      "Epoch 18/30\n",
      "512/512 - 75s - 146ms/step - loss: 0.4095 - mse: 0.4095 - val_loss: 0.1392 - val_mse: 0.1392\n",
      "Epoch 19/30\n",
      "512/512 - 75s - 146ms/step - loss: 0.3978 - mse: 0.3978 - val_loss: 0.1353 - val_mse: 0.1353\n",
      "Epoch 20/30\n",
      "512/512 - 78s - 153ms/step - loss: 0.4127 - mse: 0.4127 - val_loss: 0.1659 - val_mse: 0.1659\n",
      "Epoch 21/30\n",
      "512/512 - 80s - 156ms/step - loss: 0.4048 - mse: 0.4048 - val_loss: 0.1540 - val_mse: 0.1540\n",
      "Epoch 22/30\n",
      "512/512 - 79s - 155ms/step - loss: 0.3952 - mse: 0.3952 - val_loss: 0.1509 - val_mse: 0.1509\n",
      "Epoch 23/30\n",
      "512/512 - 81s - 157ms/step - loss: 0.4207 - mse: 0.4207 - val_loss: 0.1373 - val_mse: 0.1373\n",
      "Epoch 24/30\n",
      "512/512 - 83s - 162ms/step - loss: 0.4051 - mse: 0.4051 - val_loss: 0.1476 - val_mse: 0.1476\n",
      "Epoch 25/30\n",
      "512/512 - 83s - 162ms/step - loss: 0.4023 - mse: 0.4023 - val_loss: 0.1491 - val_mse: 0.1491\n",
      "Epoch 26/30\n",
      "512/512 - 85s - 166ms/step - loss: 0.3894 - mse: 0.3894 - val_loss: 0.1444 - val_mse: 0.1444\n",
      "Epoch 27/30\n",
      "512/512 - 86s - 167ms/step - loss: 0.4116 - mse: 0.4116 - val_loss: 0.1473 - val_mse: 0.1473\n",
      "Epoch 28/30\n",
      "512/512 - 85s - 166ms/step - loss: 0.4013 - mse: 0.4013 - val_loss: 0.1466 - val_mse: 0.1466\n",
      "Epoch 29/30\n",
      "512/512 - 88s - 171ms/step - loss: 0.4150 - mse: 0.4150 - val_loss: 0.1457 - val_mse: 0.1457\n",
      "Epoch 30/30\n",
      "512/512 - 88s - 173ms/step - loss: 0.4022 - mse: 0.4022 - val_loss: 0.1419 - val_mse: 0.1419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7efd7c43f730>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "clipGenerator = sampleGenerator(mergedSpeech, clipLength, noisingFactor, normalizingFactor, batchSize=32)\n",
    "validationClipGenerator = sampleGenerator(validationSpeech, clipLength, noisingFactor, normalizingFactor, batchSize=256)\n",
    "\n",
    "# Train the model\n",
    "\n",
    "denoiser.fit(clipGenerator, \n",
    "              steps_per_epoch=512, \n",
    "              epochs=30, \n",
    "              validation_data=validationClipGenerator, \n",
    "              validation_steps=16,\n",
    "              verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# Test the model on a noisy clip from the test dataset\n",
    "def sequentialPredict(data, subsequenceLength, stride):\n",
    "    assert stride <= subsequenceLength\n",
    "    batchSize = 32\n",
    "    batchedData = np.empty((int(np.ceil(data.shape[0] - subsequenceLength) / stride) + 1, subsequenceLength))\n",
    "    startIndices = np.empty((batchedData.shape[0],), dtype=np.int32)\n",
    "    for i in range(0, batchedData.shape[0]):\n",
    "        startIndex = i * stride\n",
    "        if startIndex > data.shape[0] - subsequenceLength:\n",
    "            startIndex = data.shape[0] - subsequenceLength\n",
    "        batchedData[i] = data[startIndex:startIndex + subsequenceLength] / normalizingFactor\n",
    "        startIndices[i] = startIndex\n",
    "    processedBatches = denoiser.predict(batchedData, batch_size=batchSize) * normalizingFactor\n",
    "\n",
    "    finalData = np.zeros(data.shape)\n",
    "    hitCounter = np.zeros(data.shape)\n",
    "    for i in range(0, batchedData.shape[0]):\n",
    "        finalData[startIndices[i]:startIndices[i] + subsequenceLength] += processedBatches[i]\n",
    "        hitCounter[startIndices[i]:startIndices[i] + subsequenceLength] += 1\n",
    "    finalData = np.divide(finalData, hitCounter)\n",
    "    return finalData.astype(np.int16)\n",
    "\n",
    "testClip = testClips[0]  # Choose a clip from the test set\n",
    "noisedClip = (testClip + np.random.normal(loc=0, scale=noisingFactor * normalizingFactor, size=testClip.shape)).astype(np.int16)\n",
    "\n",
    "# Denoise the clip\n",
    "predicted = sequentialPredict(noisedClip, clipLength, stride=clipLength // 2)\n",
    "\n",
    "# Save the denoised output\n",
    "scipy.io.wavfile.write(\"predicted_test.wav\", dataRate, predicted)\n",
    "scipy.io.wavfile.write(\"original_test.wav\", dataRate, testClips[0])\n",
    "scipy.io.wavfile.write(\"noised_test.wav\", dataRate, noisedClip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./output/FFT/denoised_combined_clnsp0.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp0.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp1.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp1.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp10.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp10.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp11.wav...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16456/2399811111.py:38: RuntimeWarning: invalid value encountered in divide\n",
      "  return (processed_data / hit_counts).astype(np.int16)\n",
      "/tmp/ipykernel_16456/2399811111.py:38: RuntimeWarning: invalid value encountered in cast\n",
      "  return (processed_data / hit_counts).astype(np.int16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp11.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp12.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp12.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp13.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp13.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp14.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp14.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp15.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp15.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp16.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp16.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp17.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp17.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp18.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp18.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp19.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp19.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp2.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp2.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp20.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp20.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp3.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp3.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp4.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp4.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp5.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp5.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp6.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp6.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp7.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp7.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp8.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp8.wav\n",
      "Processing ./output/FFT/denoised_combined_clnsp9.wav...\n",
      "Saved denoised file to ./output/FFT+DNN/denoised_combined_clnsp9.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io.wavfile as wavfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load audio file\n",
    "def load_audio_file(file_path):\n",
    "    rate, data = wavfile.read(file_path)  # Load the .wav file\n",
    "    return rate, data\n",
    "\n",
    "# Function to convert stereo audio to mono\n",
    "def stereo_to_mono(stereo_audio):\n",
    "    if len(stereo_audio.shape) == 2:  # Check if audio is stereo\n",
    "        mono_audio = stereo_audio.mean(axis=1)  # Average the two channels\n",
    "        return mono_audio.astype(np.int16)  # Convert back to int16 if necessary\n",
    "    return stereo_audio  # If it's already mono, return it as is\n",
    "\n",
    "# Function for sequential prediction (actual processing logic)\n",
    "def sequentialPredict(data, subsequenceLength, stride):\n",
    "    assert stride <= subsequenceLength, \"Stride must be less than or equal to the subsequence length.\"\n",
    "    batchSize = 32  # Example batch size\n",
    "    total_batches = (len(data) - subsequenceLength) // stride + 1\n",
    "    processed_data = np.zeros(len(data), dtype=np.float32)\n",
    "    hit_counts = np.zeros(len(data), dtype=np.float32)\n",
    "\n",
    "    for batch_idx in range(total_batches):\n",
    "        start_idx = batch_idx * stride\n",
    "        end_idx = start_idx + subsequenceLength\n",
    "        if end_idx > len(data):\n",
    "            end_idx = len(data)\n",
    "            start_idx = end_idx - subsequenceLength\n",
    "\n",
    "        subsequence = data[start_idx:end_idx]\n",
    "        denoised_subsequence = subsequence * 0.95  # Example denoising factor\n",
    "        processed_data[start_idx:end_idx] += denoised_subsequence\n",
    "        hit_counts[start_idx:end_idx] += 1\n",
    "\n",
    "    return (processed_data / hit_counts).astype(np.int16)\n",
    "\n",
    "# Function to process all files in a folder\n",
    "def process_folder(input_folder, output_folder, clipLength=1024, stride=512):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.wav'):  # Process only .wav files\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            output_path = os.path.join(output_folder, f\"{file_name}\")\n",
    "\n",
    "            print(f\"Processing {input_path}...\")\n",
    "            dataRate, testClip = load_audio_file(input_path)\n",
    "\n",
    "            # Convert stereo to mono if necessary\n",
    "            testClip = stereo_to_mono(testClip)\n",
    "\n",
    "            # Apply DNN-based denoising\n",
    "            denoised_audio = sequentialPredict(testClip, clipLength, stride)\n",
    "\n",
    "            # Save the denoised output\n",
    "            wavfile.write(output_path, dataRate, denoised_audio)\n",
    "            print(f\"Saved denoised file to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = './output/FFT/'  # Input folder\n",
    "    output_folder = './output/FFT+DNN/'  # Output folder\n",
    "\n",
    "    process_folder(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technique 3 (DNN only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp0.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp0.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp1.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp1.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp10.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp10.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp11.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp11.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp12.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp12.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp13.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp13.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp14.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp14.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp15.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp15.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp16.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp16.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp17.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp17.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp18.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp18.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp19.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp19.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp2.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp2.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp20.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp20.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp3.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp3.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp4.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp4.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp5.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp5.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp6.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp6.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp7.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp7.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp8.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp8.wav\n",
      "Processing ./MS-SNSD-master/combined_test/combined_clnsp9.wav...\n",
      "Saved denoised file to ./output/DNN/denoised_combined_clnsp9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16456/1175347463.py:38: RuntimeWarning: invalid value encountered in divide\n",
      "  return (processed_data / hit_counts).astype(np.int16)\n",
      "/tmp/ipykernel_16456/1175347463.py:38: RuntimeWarning: invalid value encountered in cast\n",
      "  return (processed_data / hit_counts).astype(np.int16)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io.wavfile as wavfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load audio file\n",
    "def load_audio_file(file_path):\n",
    "    rate, data = wavfile.read(file_path)  # Load the .wav file\n",
    "    return rate, data\n",
    "\n",
    "# Function to convert stereo audio to mono\n",
    "def stereo_to_mono(stereo_audio):\n",
    "    if len(stereo_audio.shape) == 2:  # Check if audio is stereo\n",
    "        mono_audio = stereo_audio.mean(axis=1)  # Average the two channels\n",
    "        return mono_audio.astype(np.int16)  # Convert back to int16 if necessary\n",
    "    return stereo_audio  # If it's already mono, return it as is\n",
    "\n",
    "# Function for sequential prediction (actual processing logic)\n",
    "def sequentialPredict(data, subsequenceLength, stride):\n",
    "    assert stride <= subsequenceLength, \"Stride must be less than or equal to the subsequence length.\"\n",
    "    batchSize = 32  # Example batch size\n",
    "    total_batches = (len(data) - subsequenceLength) // stride + 1\n",
    "    processed_data = np.zeros(len(data), dtype=np.float32)\n",
    "    hit_counts = np.zeros(len(data), dtype=np.float32)\n",
    "\n",
    "    for batch_idx in range(total_batches):\n",
    "        start_idx = batch_idx * stride\n",
    "        end_idx = start_idx + subsequenceLength\n",
    "        if end_idx > len(data):\n",
    "            end_idx = len(data)\n",
    "            start_idx = end_idx - subsequenceLength\n",
    "\n",
    "        subsequence = data[start_idx:end_idx]\n",
    "        denoised_subsequence = subsequence * 0.95  # Example denoising factor\n",
    "        processed_data[start_idx:end_idx] += denoised_subsequence\n",
    "        hit_counts[start_idx:end_idx] += 1\n",
    "\n",
    "    return (processed_data / hit_counts).astype(np.int16)\n",
    "\n",
    "# Function to process all files in a folder\n",
    "def process_folder(input_folder, output_folder, clipLength=1024, stride=512):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.wav'):  # Process only .wav files\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            output_path = os.path.join(output_folder, f\"denoised_{file_name}\")\n",
    "\n",
    "            print(f\"Processing {input_path}...\")\n",
    "            dataRate, testClip = load_audio_file(input_path)\n",
    "\n",
    "            # Convert stereo to mono if necessary\n",
    "            testClip = stereo_to_mono(testClip)\n",
    "\n",
    "            # Apply DNN-based denoising\n",
    "            denoised_audio = sequentialPredict(testClip, clipLength, stride)\n",
    "\n",
    "            # Save the denoised output\n",
    "            wavfile.write(output_path, dataRate, denoised_audio)\n",
    "            print(f\"Saved denoised file to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = './MS-SNSD-master/combined_test/'  # Input folder\n",
    "    output_folder = './output/DNN/'  # Output folder\n",
    "\n",
    "    process_folder(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pesq in /var/home/noshamedevil/miniconda3/envs/tf/lib/python3.10/site-packages (0.0.4)\n",
      "Requirement already satisfied: pystoi in /var/home/noshamedevil/miniconda3/envs/tf/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: numpy in /var/home/noshamedevil/miniconda3/envs/tf/lib/python3.10/site-packages (from pystoi) (2.0.2)\n",
      "Requirement already satisfied: scipy in /var/home/noshamedevil/miniconda3/envs/tf/lib/python3.10/site-packages (from pystoi) (1.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pesq pystoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged metrics and comparison graph saved in ./comparison_results/.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from pesq import pesq  # Ensure to install using `pip install pesq`\n",
    "from pystoi import stoi  # Ensure to install using `pip install pystoi`\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load audio file\n",
    "def load_audio_file(file_path, target_sr=16000):\n",
    "    signal, sr = librosa.load(file_path, sr=target_sr)\n",
    "    return signal, sr\n",
    "\n",
    "# Function to calculate SNR\n",
    "def calculate_snr(original_signal, denoised_signal):\n",
    "    signal_power = np.sum(original_signal ** 2)\n",
    "    noise_power = np.sum((original_signal - denoised_signal) ** 2)\n",
    "    snr = 10 * np.log10(signal_power / noise_power)\n",
    "    return snr\n",
    "\n",
    "# Function to calculate MSE\n",
    "def calculate_mse(original_signal, denoised_signal):\n",
    "    return np.mean((original_signal - denoised_signal) ** 2)\n",
    "\n",
    "# Function to compute and aggregate metrics for all files\n",
    "def aggregate_metrics(input_folder, output_folder, target_sr=16000):\n",
    "    methods = [\"STFT\", \"FFT+DNN\", \"DNN\", \"FFT\"]\n",
    "    aggregated_metrics = {method: {\"snr\": [], \"mse\": [], \"pesq\": [], \"stoi\": []} for method in methods}\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.wav'):  # Only process WAV files\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            original_signal, sr = load_audio_file(input_path, target_sr)\n",
    "\n",
    "            for method in methods:\n",
    "                denoised_path = os.path.join(output_folder, method, f\"denoised_{file_name}\")\n",
    "                if os.path.exists(denoised_path):\n",
    "                    denoised_signal, _ = load_audio_file(denoised_path, target_sr)\n",
    "\n",
    "                    # Align lengths for metrics\n",
    "                    min_length = min(len(original_signal), len(denoised_signal))\n",
    "                    aligned_original = original_signal[:min_length]\n",
    "                    aligned_denoised = denoised_signal[:min_length]\n",
    "\n",
    "                    # Compute metrics\n",
    "                    snr = calculate_snr(aligned_original, aligned_denoised)\n",
    "                    mse = calculate_mse(aligned_original, aligned_denoised)\n",
    "                    pesq_score = pesq(target_sr, aligned_original, aligned_denoised, 'wb')\n",
    "                    stoi_score = stoi(aligned_original, aligned_denoised, target_sr)\n",
    "\n",
    "                    # Append metrics\n",
    "                    aggregated_metrics[method][\"snr\"].append(snr)\n",
    "                    aggregated_metrics[method][\"mse\"].append(mse)\n",
    "                    aggregated_metrics[method][\"pesq\"].append(pesq_score)\n",
    "                    aggregated_metrics[method][\"stoi\"].append(stoi_score)\n",
    "\n",
    "    # Average metrics across all files\n",
    "    averaged_metrics = {\n",
    "        method: {\n",
    "            \"snr\": np.mean(values[\"snr\"]),\n",
    "            \"mse\": np.mean(values[\"mse\"]),\n",
    "            \"pesq\": np.mean(values[\"pesq\"]),\n",
    "            \"stoi\": np.mean(values[\"stoi\"])\n",
    "        }\n",
    "        for method, values in aggregated_metrics.items()\n",
    "    }\n",
    "\n",
    "    return averaged_metrics\n",
    "\n",
    "# Function to plot averaged metrics\n",
    "def plot_averaged_metrics(averaged_metrics, output_folder):\n",
    "    methods = list(averaged_metrics.keys())\n",
    "    snr_values = [averaged_metrics[method][\"snr\"] for method in methods]\n",
    "    mse_values = [averaged_metrics[method][\"mse\"] for method in methods]\n",
    "    pesq_values = [averaged_metrics[method][\"pesq\"] for method in methods]\n",
    "    stoi_values = [averaged_metrics[method][\"stoi\"] for method in methods]\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # SNR Comparison\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.bar(methods, snr_values, color='blue')\n",
    "    plt.title(\"Average SNR Comparison (dB)\")\n",
    "    plt.ylabel(\"SNR (dB)\")\n",
    "\n",
    "    # MSE Comparison\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.bar(methods, mse_values, color='orange')\n",
    "    plt.title(\"Average MSE Comparison\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "\n",
    "    # PESQ Comparison\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.bar(methods, pesq_values, color='green')\n",
    "    plt.title(\"Average PESQ Comparison\")\n",
    "    plt.ylabel(\"PESQ Score\")\n",
    "\n",
    "    # STOI Comparison\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.bar(methods, stoi_values, color='purple')\n",
    "    plt.title(\"Average STOI Comparison\")\n",
    "    plt.ylabel(\"STOI Score\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, \"averaged_metrics_comparison.png\"))\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"./MS-SNSD-master/combined_test/\"  # Input folder for original files\n",
    "    output_folder = \"./output/\"  # Output folder for denoised files\n",
    "    comparison_output_folder = \"./comparison_results/\"  # Folder to save the results\n",
    "\n",
    "    if not os.path.exists(comparison_output_folder):\n",
    "        os.makedirs(comparison_output_folder)\n",
    "\n",
    "    # Aggregate and average metrics\n",
    "    averaged_metrics = aggregate_metrics(input_folder, output_folder)\n",
    "\n",
    "    # Plot and save averaged metrics\n",
    "    plot_averaged_metrics(averaged_metrics, comparison_output_folder)\n",
    "\n",
    "    print(f\"Averaged metrics and comparison graph saved in {comparison_output_folder}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 48\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metrics_df\u001b[38;5;241m.\u001b[39mto_string(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics_df\n\u001b[1;32m---> 48\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m display_filewise_metrics(\u001b[43minput_folder\u001b[49m, output_folder)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_folder' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Ensure you have pandas installed: `pip install pandas`\n",
    "\n",
    "# Function to compute and display file-wise metrics in a table\n",
    "def display_filewise_metrics(input_folder, output_folder, target_sr=16000):\n",
    "    methods = [\"STFT\", \"FFT+DNN\", \"DNN\"]\n",
    "    metrics_table = []\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.wav'):  # Only process WAV files\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            original_signal, sr = load_audio_file(input_path, target_sr)\n",
    "\n",
    "            for method in methods:\n",
    "                denoised_path = os.path.join(output_folder, method, f\"denoised_{file_name}\")\n",
    "                if os.path.exists(denoised_path):\n",
    "                    denoised_signal, _ = load_audio_file(denoised_path, target_sr)\n",
    "\n",
    "                    # Align lengths for metrics\n",
    "                    min_length = min(len(original_signal), len(denoised_signal))\n",
    "                    aligned_original = original_signal[:min_length]\n",
    "                    aligned_denoised = denoised_signal[:min_length]\n",
    "\n",
    "                    # Compute metrics\n",
    "                    snr = calculate_snr(aligned_original, aligned_denoised)\n",
    "                    mse = calculate_mse(aligned_original, aligned_denoised)\n",
    "                    pesq_score = pesq(target_sr, aligned_original, aligned_denoised, 'wb')\n",
    "                    stoi_score = stoi(aligned_original, aligned_denoised, target_sr)\n",
    "\n",
    "                    # Append results to the table\n",
    "                    metrics_table.append({\n",
    "                        \"File Name\": file_name,\n",
    "                        \"Method\": method,\n",
    "                        \"SNR (dB)\": snr,\n",
    "                        \"MSE\": mse,\n",
    "                        \"PESQ\": pesq_score,\n",
    "                        \"STOI\": stoi_score\n",
    "                    })\n",
    "\n",
    "    # Convert to a pandas DataFrame\n",
    "    metrics_df = pd.DataFrame(metrics_table)\n",
    "\n",
    "    # Print the metrics table\n",
    "    print(\"\\nFile-wise Metrics:\")\n",
    "    print(metrics_df.to_string(index=False))\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "metrics_df = display_filewise_metrics(input_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
